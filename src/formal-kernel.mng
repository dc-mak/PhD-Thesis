% vim: ft=tex
\chapter{Kernel CN:\ Grammar}%
\label{chap:kernel-grammar}

\margintoc%

\kl{CN} and \kl{Kernel} CN have different grammars. This is because \kl{CN} is
intended to be used by C programmers, whereas \kl{Kernel} CN is for type
theorists, thus more convenient to understand and work with as a formalism. The
primary differences are (a) \kl{CN} is implemented over (a version of)
\kl{Core}, whereas the \kl{kernel} is defined over a let-normalised
\kl{ResCore} (b) \kl{CN}'s grammar of types is close to the surface syntax and
so each construct serves many purposes whereas the \kl{kernel}'s grammar of types
is more traditional and each construct only serves one purpose.

In this chapter I will present the relevant parts of \kl{CN}'s syntax of
predicate definitions and assertions, and the \kl{kernel}'s syntax of types and
relevant terms, with a particular focus on explicit resource terms. Since
the \kl{CN} implementation requires users to manually unfold recursive
pure functions, I do not discuss this feature, and assume any constraints
relevant to it have been placed into the elaborated \kl{ResCore} program.
I also omit discussion of typing rules for SMT terms, including handling
datatype declarations.

\section{Kernel CN types}

\cref{fig:surface-cn-syntax} shows the grammar\sidenote{} of \kl{CN}'s
surface syntax. Of note are the fact that $[[spec]]$ may terminate with a $[[return term]]$,
as required by predicate definitions but not by function specifications, or it
may not (represented here with a $[[cdot]]$).

\begin{figure*}[tpb]
    \small
    \grammartabularSTY{
        \cnspec{}\cninterrule{}
        \cnpredXXipred{}\cninterrule{}
        \cnpredXXterm{}\cninterrule{}
        \cnipredXXterm{}\cninterrule{}
    }
    \caption{Surface CN syntax for predicate, requires and ensures bodies.}\label{fig:surface-cn-syntax}
\end{figure*}

Recall that the specifications are not freestanding, but are defined within the
scope of either C function parameters, or of predicate parameters, as shown
in~\cref{fig:func-pred-def}.
\begin{figure}[htp]
    \small
    \grammartabularSTY{
        \cnfuncXXdef{}\cninterrule{}
        \cnfuncXXspec{}\cninterrule{}
        \cnpredXXdef{}\cnafterlastrule{}
    }
    \caption{Surface CN syntax for function specifications and predicate
        definitions.}\label{fig:func-pred-def}
\end{figure}

\cref{fig:kernel-fun-ret} shows the grammar of function types $[[ fon ]]$ which
include both pre- and postconditions, and return types $[[ ret ]]$, which
represent postconditions. The structure of the types makes explicit the scoping
implicit in the surface syntax. Function parameters $[[ct id;]]$ are mapped to
$[[ pi x : to_base ( ct ) .: fon ]]$, and C return types $[[ct']]$ and values,
bound here with $[[y]]$\sidenote{In the implementation, this identifier is
hardcoded to be the \cnline{return} keyword in postconditions.} is mapped to
$[[sigma y : to_base ( ct' ) .: ret ]]$. And lastly, the placement of $[[ret]]$
inside $[[fon]]$, makes it clear that postconditions may also refer to variables
bound in the precondition, and allows for symbolic or concrete function
arguments to be substituted in (see~\nameref{sec:spine-judgement}).

\begin{figure}[htp]
    \small
    \grammartabularSTY{%
        \cnret{}\cninterrule{}
        \cnfon{}\cnafterlastrule{}
    }
    \caption{\kl{Kernel CN} function and return types.}\label{fig:kernel-fun-ret}
\end{figure}

In order, both function $[[fon]]$ and return $[[ret]]$ types include:
quantification over computational (program) values, quantification over logical
(ghost) values, separating implication/conjunction for assertions about the
heap, and logical implication/conjunction for pure assertions (in a linear
context, about an empty heap).

Though this seems like a large departure from the syntax given in
\cref{fig:cn-grammar}, the mapping into this is straightforward, and helps
clarify what each \kl{CN} surface construct represents in more familiar,
type theoretic terms.

Before I explain this mapping, there is one more key component left to explain:
\emph{resource types}. As seen in~\cref{fig:kernel-res}, they are type for
separation logic assertions, which will be treated linearly. The constructs are
quite standard, except for the only mention of branching in any of the types,
with the \emph{ordered} disjunction, to prevent the need for backtracking,
rather than the usual $\vee{}$.

For ease of implementation and formalisation, we do not have branching for pre-
and postconditions and function/return types, but this does not affect
expressiveness because these can be embedded into the resource types. Note that
in the formalisation, the branching is not restricted to the top-level in
predicate definitions, but can occur directly in function types, and can be
arbitrarily nested. This makes defining predicates to represent tagged unions
more succinct, and allows for opening predicates in more cases.

Predicates $[[ pred ]]$ and iterated predicates $[[ ipred ]]$ are simple
$[[ pred_term ]]$ and $[[ipred_term]]$ with output arguments, % chktex 25
as seen in~\cref{fig:kernel-ipred}.
I will explain why I factored out $[[pred_term]]$ and $[[ipred_term]]$ in % chktex 25
\nameref{sec:res-terms}. Where the surface syntax is written \cninline{RW} and
\cninline{W}, I write it as $[[ Owned < Init , ct > ]]$ and
$[[ Owned < Uninit , ct > ]]$ respectively. \sidenote{Prior versions of this
    system allowed for more fine-grained control over reading and writing
    \emph{partially} (and completely) uninitialised reads of
    structs/unions. However,
    \href{https://www.cl.cam.ac.uk/~pes20/cerberus/notes98-2018-04-21-uninit-v4.html\#reads-of-partially-uninitialised-structsunions-as-a-whole}{the
    precise semantics of such a scheme is unresolved} and it is
    considerably simpler, and for verifying code so far, sufficient, to be
    conservative in this regard.}\label{sn:partial-init-read}

\begin{figure*}
    \small
    \raggedright{}
    \begingroup%
    \renewcommand{\grammartabularSTY}[1]{\grammartabularWrapComment{0.7\textwidth}{#1}}
    \grammartabularSTY{%
        \cnpredXXname{}\cninterrule{}
        \cnpred{}\cninterrule{}
        \cnipred{}\cnafterlastrule{}
    }%
    \endgroup%
    \caption{\kl{Kernel CN} predicate and iterated predicate terms (without
        output arguments) and types (with output arguments). The formalisation
        is set up with some syntactic sugar (marked with $\mathsf{S}$) to make
        the meanings of these constructs more intuitive.}\label{fig:kernel-ipred}

\end{figure*}

\begin{figure*}
    \small
    \grammartabularSTY{%
        \cnres{}\cnafterlastrule{}
    }
    \caption{\kl{Kernel CN} resource types, a linear type for separation logic
        assertions.}\label{fig:kernel-res}
\end{figure*}

\section{Desugaring \kl{CN} types into \kl{kernel} types}\label{sec:desugaring}

All judgements in the formalisation which have a natural bidirectional
interpretation have the information they are synthesising highlighted with
\colorbox{pink!30}{light pink} background. The grammars presented below will
refer to $[[term]]$, $[[iguard]]$, $[[ptrt]]$, $[[iarg]]$, $[[oarg]]$
(and later, $[[alloct]]$). These are all simply aliases for pure (SMT) terms, used
so that the roles of these terms in different productions, especially ones
productions which refer to multiple instances of them, are clearer. \intro{Base
types}, represented by $[[ base_type ]]$ are simply the types of such terms. % chktex 25

Desugaring \kl{CN} types into \kl{Kernel CN} starts with the C functions, which
map their parameters into computational variables in function types, or with
predicate definitions, which map their parameters into essentially a
$\lambda$-abstraction over a resource type (\cref{fig:prepost-to-kernel}). To
be clear, this is merely quantifying over pure (SMT) terms in the type, rather
than any higher-order assertions about the shape of the heap.

\begin{figure*}[tp]
    \small
    \raggedright{}
    \cndefnUserXXFuncXXTo{}
    \cndefnUserXXPredXXTo{}
    \caption{\kl{CN} to \kl{Kernel CN} pre- and postcondition and predicate
        definition desugaring. For the C functions, each C argument is bound to
        a computational argument, with a base type $\beta_\tau$ corresponding
        to the C type $\tau$. Predicate definitions simply abstract pure (SMT)
        terms over resources.}\label{fig:prepost-to-kernel}
\end{figure*}

Desugaring preconditions into function types requires the postcondition to be
desugared first; because that is similar to precondition desugaring, I will
omit it for space. Abbreviations are simply substituted into the function
type.\sidenote{In the implementation, for better error messages, they are bound
to a fresh variable and constrained with an equality constraint.}\label{sn:abbrev}
Constraints are mapped into logical implications. The formalisation can handle
ifs directly in the precondition, unlike the surface syntax which allows ifs to be placed
only at the top-level of a predicate (\cref{sec:restriction-branching}).

The monadic binding \cninline{take id = ..} is always translated into a logical % chktex 26
quantification over the output argument of the (iterated) predicates. Because
all the predicate definitions are guaranteed to be precise, all the logical
quantifications can be inferred when required.

\begin{figure*}[tp]
    \small
    \raggedright{}
    \cndefnUserXXSpecXXToXXArg{}
    \caption{\kl{CN} to \kl{Kernel CN} precondition desugaring. I use $x \equiv e$
        to introduce $x$ as an abbreviation for $e$ when $e$ is a long term.
        Postcondition desugaring is similar, and thus omitted.}\label{fig:precond-to-kernel}
\end{figure*}

Desugaring predicate definitions is similar. Because the grammar is used in two
contexts, inside a pre- or postcondition where a return is not allowed, and in
a predicate definition where a return is allowed, the desugaring is
parameterised over whether or not a return is expected. If one is not, then the
resource is simply an $[[ emp ]]$, otherwise it is an equality constraint,
as shown in \cref{fig:monad-sl}. Outputs of (iterated) predicates are always
assumed to be of the shape of a record for uniformity, which I will justify
later. Abbreviations are also substituted in.\sidenote{As in note~\ref{sn:abbrev}.}
Because pure (SMT) terms are syntactically stratified out of
the impure ones, they are embeded directly into a resource type (separation
logic assertion) with $\astRef{}$. Ifs in the syntax are translated into ifs in
the resource type grammar, with some adjustment based on whether it occurs in a
terminal place; no returns are expected/allowed in non-terminal
ifs. This restriction side steps the need for a more complicated
destination-passing style~\sidecite{shaikhha2017destination} transformation to
translate the semantics of early-returns into precise separation logic
assertions. Lastly, as before, the monadic binding \cninline{take id = ..} is % chktex 26
always translated into a logical quantification over the output argument of the
(iterated) predicate.

\begin{figure*}[tp]
    \small
    \raggedright{}
    \cndefnUserXXSpecXXToXXRes{}
    \caption{\kl{CN} to \kl{Kernel CN} user-defined predicate desugaring.}\label{fig:pred-to-kernel}
\end{figure*}

\section{ResCore}\label{sec:rescore}

Not only is the formalisation defined over a desugared representation of types
from the surface \kl{CN} syntax, it is also defined over the let-normal form of
the \kl{Core} grammar
(\cref{fig:pure-core-grammar,fig:effectful-core-grammar}). By let-normal, I
mean an A-normal~\sidecite{flanagan1993essence} form which is closed under
substitution.

Specifically, it syntactically stratifies values and
expressions from which we would like to \emph{synthesise} type information, and
statements against which we would like to \emph{check} a
given type. This applies to both pure and effectful fragments, leading to a
four-fold distinction in the let-normal form of the grammar.

This dramatically simplifies presenting and working with the type system, because:
\begin{itemize}
    \item \coreinline{undef()}. In typing this, it is necessary to give is a % chktex 36
        checking rule, since control flow is required to not reach that point
        (\cref{fig:core-ub-typing}).
    \item \textbf{Control flow}. Here too, we would also very much like to use
        a checking rule, since this would sidestep the need to synthesise
        least-upper bound types for join-points after all \kl{Core}
        \coreinline{if}-expressions (or require annotations on them), at the
        cost of accepting a combinatorial explosion in typing all subsequent
        expressions.
    \item \textbf{Lets}. In typing these, we would also very much like to use a
        \emph{synthesis} rule for the bound expression, since that removes the
        need for an annotation to be placed on the binder there.
    \item \textbf{Memory actions}. These too are well-suited to synthesis, since
        they can manipulate they manipulate the resource context via the
        resources types they will synthesise.
\end{itemize}

Initial implementations of \kl{CN} did a full A-normalisation of Core, but this resulted
in far too many logical variables being created (one for each intermediate
sub-expression) and these were very difficult to relate back to the source
program in concrete counter-examples produced by the SMT
solver.\sidenote{Location information was not tracked properly either so this
was doomed.} Hence, this was
removed.\sidenote{\href{https://github.com/rems-project/cerberus/commit/21808139bda2ee320756c71eb22dbd57d0986f97}{Commit
21808139.}}\label{sn:rm-anorm}

The way that \kl{CN} currently manages the flow of information is by explicitly
passing around continuations; when it comes across any expression which is
treated as statement in \kl{ResCore}, it simply does the appropriate
checks and then \emph{drops} the continuation.\sidenote{\href{https://github.com/rems-project/cerberus/commit/350fefc675626dcc69c7adc9edea30ff9687b752}{Commit 350fefc6.}}\label{sn:use-conts}
This makes the code more fragile but saves the need for maintaining another large
syntax tree which needs pretty-printers, debug printers, source location
mappings and so on.

Since it would require more complex fractional permissions, I left out
let-normalising the constructs related to C's loose evaluation order.\sidenote{%
\coreinline{neg()}, \coreinline{unseq()}, \coreinline{let weak}, % chktex 36
\coreinline{let strong}, \coreinline{bound()}, \coreinline{nd()}, % chktex 36
\coreinline{par()}.} However, this also means the formalisation glosses % chktex 36
over the fact that those constructs can contain each other in a semantically
meaningful way, such that flattening out that nesting seems impossible. A
solution would be to require type annotations on any situation which requires
statements to be nested inside one another.\sidenote{Nested (and therefore,
annotated) statements are required only for proving type
preservation for calls to pure Core functions, effectful Core
procedures, and elaborated C functions.} I will demonstrate in
\nameref{chap:kernel-alternative}, it seems very difficult to avoid some sort
of normalisation (and associated control flow explosion) somewhere in the type
system in the presence of join-points and early returns in sub-expressions.

Pure expressions include things such as pure values,
datatype values, pointer arithmetic for arrays (in \kl{de facto}, not \kl{ISO})
and struct/union members, boolean negation, binary operations and relations, function
calls and assertions. Pure statements are shown in
\cref{fig:kernel-pstmt}. As mentioned earlier, constructs where control flow
should not reach, such as \coreinline{undef()} must be in a checking % chktex 36
judgement, so are part of pure statement.

\begin{figure*}
    \small
    \grammartabularSTY{%
        \cnpstmt{}\cnafterlastrule{}
    }
    \caption{Pure statements in ResCore.}\label{fig:kernel-pstmt}
\end{figure*}

Effectful expression (\cref{fig:kernel-expr}), include memory actions, memory
operations, C function calls and Core procedure calls.

\begin{figure}[htp]
    \small
    \grammartabularSTY{%
        \cnexpr{}\cnafterlastrule{}
    }
    \caption{Effectful expressions in ResCore.}\label{fig:kernel-expr}
\end{figure}

Effectful statements include \kl{return terms}, pure statements, bound effectful
expressions, standard conditional and pattern-matching constructs and the
\coreinline{run} operator (\cref{fig:effectful-core-grammar}).

\begin{figure*}[tp]
    \small
    \grammartabularSTY{%
        \cnretXXterm{}\cninterrule{}
        \cnstmt{}\cnafterlastrule{}
    }
    \caption{Effectful statements in ResCore.}\label{fig:kernel-stmt}
\end{figure*}

\section{Resource terms}\label{sec:res-terms}

One of the key initial motivations for formalising (and ultimately
implementing) a smaller kernel for \kl{CN} was to have a stronger safety net
underneath its resource inference algorithm, both at the time and for all
future inference algorithms. The hope was that this would allow us to iterate
quickly and boldly on the algorithms, with much less worry about introducing
unsoundness.

This did not materialise because \kl{CN} moved away from A-normalising
\kl{Core}, adopted a continuation-passing style, and changed its approach to
resource inference.\sidenote{See notes~\ref{sn:rm-anorm},~\ref{sn:use-conts}
and~\ref{sn:new-inf}} Another large hurdle was that it would have required
significant engineering effort to refactor the internal \intro[AST]{abstract
syntax trees} (ASTs).

Yet, the effort was still fruitful since it brought extra clarity to questions
around the implementation (\nameref{chap:inform-impl}) and inspired ideas on
how to feasibly and gradually transition the most subtle and complex parts of
\kl{CN} (either now, or in the future) to a
proof-assistant (\nameref{sec:better-foundations}).

The key concept which makes this possible is to include explicit (linearly
typed) terms for both resources \emph{and operations on them} in the grammar of
\kl{ResCore}. Though this is not a new
concept~\sidecite{xi1999dependent,cui2005ats,ahmed2007l3}, its application in a
separation logic settings appears to be so, because these sorts of
manipulations are usually done manually in an interactive proof-assistant and
recorded as tactics in a proof script \emph{external} to the program being
verified. In {kernel CN}, these \intro{resource terms} serve many purposes:
\begin{itemize}
    \item \textbf{Resource annotation.} They act as resource type annotations
        on constructs which require them.
    \item \textbf{Primitives.} They clarify the smallest units of
        resources and operations on them.
    \item \textbf{Bookkeeping.} They act as a log of the sequence of operations
        required to (soundly) manipulate the resource context from one symbolic
        state to another.
\end{itemize}

Of course, as with logical (ghost) terms, resource terms must be added with
care to the language to ensure erasure; they must not affect the control flow,
the values computed, or the memory events executed. This is easy to see by the
fact that resource terms are only placed on the memory actions for reading,
writing or destroying a heap location, and for memory operations involving
pointers which require checks that pointers are live (\cref{fig:res-term-constructs}).

\begin{figure*}
    \small
    \grammartabularSTY{%
        \cnkillXXkind{}\cninterrule{}
        \cnaction{}\cninterrule{}
        \cnresXXaction{}\cninterrule{}
        \cnmemop{}\cninterrule{}
        \cnresXXmemop{}\cnafterlastrule{}
    }
    \caption{Constructs in \kl{ResCore} extended to accommodate
    explicit resource terms.}\label{fig:res-term-constructs}
\end{figure*}

To be clear, \kl{CN} \emph{users} are still not required to explicitly provide
any resource terms; they are used so that any algorithms for \emph{inferring}
them can be rephrased naturally as algorithms for \emph{elaborating} a program
\emph{without} resource annotations into one \emph{with} them.

Another advantage of having explicit resource terms in the grammar of
\kl{ResCore} is that this lets the heaps in the dynamic semantics be
represented more abstractly, whilst still precisely controlling their
transformations according to the reduction rules of the resource terms. This
additional modularity, whilst a bit confusing at this stage, will be seen to
pay off later when discussing the proof of soundness for the CN-VIP memory
object model (\cref{sec:cn-vip-soundness}).

\cref{fig:res-terms} shows the resource terms of \kl{ResCore}. There are
\emph{several} side conditions for each of the operations the terms represent,
which I will show in \nameref{sec:typing-res-terms}, but for now it suffices to
explain just the intuition. Terms $[[ emp ]]$ and
$[[ TERM ]]$ are introduction forms for the types $[[ emp ]]$ and pure
assertions $[[ term ]]$, and they have corresponding forms for eliminating
them too. Variables are also resource terms and patterns, for any resource
type. Terms $[[pred_term]]$ and $[[ipred_term]]$ introduce
$[[ pred ]]$ and $[[ ipred ]]$ types respectively (the only difference
between the two is that the latter also carry their output arguments). Angle
brackets $\langle \_ , \_ \rangle$ and $[[ pack (_, _rest ) ]]$ are % chktex 25
introduction forms for the separating conjunction $\astRef{}$ and $\exists$
types respectively, and they have corresponding eliminators too.

Ordered-disjunctions can be introduced by \emph{any} resource term, and
eliminated by any resource pattern.

The following terms are all operations on predicates.
\begin{itemize}
    \item $[[ fold _rest : pred ]]$. This supports folding the % chktex 25
        definitions of a user-defined recursive predicate.
    \item $[[ explode ( _rest ) ]]$ and $[[ implode ( _rest, tag ) ]]$. % chktex 25
        These constructs split and combine ownership of a struct from and to
        ownership of its members respectively.
    \item $[[ iterate ( _rest , n ) ]]$ and $[[ congeal ( _rest , n ) ]]$. % chktex 25
        These constructs split and combine ownership of a fixed-size array from
        and to each of its elements respectively.
\end{itemize}

The remaining terms are all operations on iterated predicates.
\begin{itemize}
    \item $[[ break ( _rest , _t ) ]]$. This indexes an iterated predicate % chktex 25
        to move a predicate out of it.
    \item $[[ glue ( _rest ) ]]$. This moves a predicate back into an % chktex 25
        iterated one.
    \item $[[ inj ( _rest , _t , ct , _ .: _iargs ) ]]$ % chktex 25
        This introduces a singleton (non-empty) iterated predicate.\sidenote{I
    chose a singleton introduction form rather than an empty one to enforce the
    invariant that all iterated predicates in the typing context are guaranteed
    to be non-empty. I do not believe this makes a material difference to
    soundness, but it reduces redundant lookups in the resource context, and
    avoids the need of inventing default values for empty arrays in the SMT
    problem. However, due to the mismatch between finite arrays in C, and total
    maps in SMT theories, the difference does seem to affect usability in the
    implementation
    (\href{https://github.com/rems-project/cerberus/issues/729}{issue \#729}).
TODO\@: allow empty arrays and require the array value to be put in the rather
term than assume default.}
    \item $[[ chop ( _rest , iguard ) ]]$. This splits an iterated % chktex 25
        predicate along a given index guard $[[ iguard ]]$.
\end{itemize}%
As mentioned in \nameref{sec:monadic-syntax}, to preserve decidability by not
inferring quantified constraints, the type system does not support merging arrays.

\begin{figure*}[tbp]
    \centering
    \small
    \grammartabularSTY{%
        \cnresXXterm{}\cninterrule{}
        \cnpredXXops{}\cninterrule{}
        \cnresXXpat{}\cnafterlastrule{}
    }
    \caption{Explicit resource terms in \kl{ResCore}.}\label{fig:res-terms}
\end{figure*}

